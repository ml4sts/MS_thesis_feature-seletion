{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1e0ce3-175b-4378-ae40-3a29c2c03616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from expttools import Experiment\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d1d25-c891-42c4-935e-e54de49a6a80",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3c690a-1686-40b7-a37e-8da703587f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorical_feature_encoder(data,features):\n",
    "    '''\n",
    "    takes a data frame and returns numerical encoding for categorical features\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    dataset: csv file \n",
    "    features : list of categorical features\n",
    "\n",
    "    Return \n",
    "    ------\n",
    "    returns : dataframe with encoded features, encoding for categorical features  \n",
    "    '''\n",
    "    enc = {}\n",
    "    \n",
    "    for f in features:\n",
    "        encoder = OrdinalEncoder()\n",
    "        data[f] = encoder.fit_transform(data[[f]]).astype(int)\n",
    "        enc[f] = encoder\n",
    "    return data, enc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4b9799-84f3-417c-aad9-f4b06ddb5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_manipulation(features_encoded_data,data,col_name,priviliged_vals):\n",
    "    '''\n",
    "    takes encoded data frame and original data to substitute an original column from original df to \n",
    "    encoded df for further analysis\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    features_encoded_data: encoded dataset \n",
    "    data : original data\n",
    "    col_name : column for manipulation. eg: if comparison is done between black and white, this piece \n",
    "    of code will remove all other races and return black as 0 white as 1 and \n",
    "    priviliged_vals: list of value/values considered as priviliged in society\n",
    "    Return \n",
    "    ------\n",
    "    returns : dataframe with encoded features containing manipulated column \n",
    "    '''\n",
    "    \n",
    "    decoded_col_name = f'{col_name}_decoded'\n",
    "    filtered_col_name = f'filtered_{col_name}'\n",
    "    \n",
    "    #priviliged_vals = ['Married-civ-spouse', 'Married-spouse-absent']\n",
    "    features_encoded_data[decoded_col_name] = data[col_name]\n",
    "    features_encoded_data[filtered_col_name] = features_encoded_data[decoded_col_name]\\\n",
    "    .isin(priviliged_vals).astype(int)\n",
    "\n",
    "    features_encoded_data = features_encoded_data.drop([decoded_col_name], axis = 1)\n",
    "\n",
    "    return features_encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4603b8-1db9-409f-9c7a-e61a50b07fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def base_model(data,target,col_name):\n",
    "    '''\n",
    "    takes feature encoded data, splits for training and test set and returns the data frame with predictions.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : encoded data\n",
    "    target : proxy target\n",
    "    col_name : column for manipulation. \n",
    "\n",
    "    Return \n",
    "    ------\n",
    "    returns : original_output -- predicted set\n",
    "    '''\n",
    "    encoded_df = data.copy()\n",
    "    x = encoded_df.drop([target], axis = 1)\n",
    "    \n",
    "    y = encoded_df[target]\n",
    "    filtered_col_name = f'filtered_{col_name}'\n",
    "    #print(filtered_col_name)\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.2, random_state = 0)\n",
    "    x_train[filtered_col_name] = x_train[filtered_col_name].apply(lambda x:1 if x>0 else 0)\n",
    "    x_test[filtered_col_name] = x_test[filtered_col_name].apply(lambda x:1 if x>0 else 0)\n",
    "    sc = StandardScaler()\n",
    "    x_train = pd.DataFrame(sc.fit_transform(x_train),columns = x_train.columns)\n",
    "    x_test = pd.DataFrame(sc.transform(x_test),columns = x_test.columns)\n",
    "    x_train[filtered_col_name] = x_train[filtered_col_name].apply(lambda x:1 if x>0 else 0)\n",
    "    x_test[filtered_col_name] = x_test[filtered_col_name].apply(lambda x:1 if x>0 else 0)\n",
    "    classifier = LogisticRegression()\n",
    "    print(x_train.columns)\n",
    "    classifier.fit(x_train.drop(filtered_col_name,axis=1), y_train) # dropping here\n",
    "    # We now need to add this array into x_test as a column for when we calculate the fairness metrics.\n",
    "    y_pred = classifier.predict(x_test.drop(filtered_col_name,axis=1))\n",
    "    x_test['target_predicted'] = y_pred\n",
    "    original_output = x_test\n",
    "    original_output['actual'] = y_test.values\n",
    "    return original_output\n",
    "\n",
    "#Q. should we drop p att while training? if we drop, it shows same accuracy for similar subset but the fairness metrics values differ which \n",
    "#I thoght can be a correct way..but I wanted to check before doing it in main file.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa353bf1-71e6-4964-8a6c-2db0fa4c8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_metrics_bc(original_output,col_name):\n",
    "    '''\n",
    "    takes prediction df and returns calculated fairness metrics \n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    original_output : original_output with prediction column\n",
    "    col_name : column for manipulation. \n",
    "\n",
    "    Return \n",
    "    ------\n",
    "    returns : fairness metrics\n",
    "    '''\n",
    "    filtered_col_name = f'filtered_{col_name}'\n",
    "\n",
    "    male_df = original_output[original_output[filtered_col_name] == 1]\n",
    "    num_of_priviliged = male_df.shape[0]\n",
    "    female_df = original_output[original_output[filtered_col_name] == 0]\n",
    "    num_of_unpriviliged = female_df.shape[0]\n",
    "\n",
    "    unpriviliged_outcomes = female_df[female_df['target_predicted'] == 1].shape[0]\n",
    "    unpriviliged = unpriviliged_outcomes/num_of_unpriviliged\n",
    "    unpriviliged\n",
    "\n",
    "    priviliged_outcomes = male_df[male_df['target_predicted'] == 1].shape[0]\n",
    "    priviliged = priviliged_outcomes/num_of_priviliged\n",
    "    priviliged\n",
    "\n",
    "    #Disparate impact\n",
    "    try:\n",
    "        disparate_impact = unpriviliged / priviliged\n",
    "    except:\n",
    "        disparate_impact = np.inf\n",
    "\n",
    "    #Statistical parity difference \n",
    "    statistical_parity_difference  = unpriviliged - priviliged\n",
    "    \n",
    "    #Equal opportunity difference\n",
    "    eod = original_output.copy()\n",
    "    eod = eod[eod['actual'] == 1] \n",
    "    eod ['true_positives'] = eod ['target_predicted'] == eod['actual']\n",
    "\n",
    "    eod_other = eod[eod[filtered_col_name]== 0]['true_positives'].mean()\n",
    "\n",
    "    eod_married_civ_absent = eod[eod[filtered_col_name] == 1]['true_positives'].mean()\n",
    "    equal_opportunity_difference  = eod_other - eod_married_civ_absent\n",
    "    \n",
    "    #accuracy\n",
    "    accuracy = (original_output['target_predicted']== original_output['actual']).mean()\n",
    "    \n",
    "    return ([disparate_impact,statistical_parity_difference,equal_opportunity_difference,accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd17f6-d4d4-4570-b078-2745a41ac21c",
   "metadata": {},
   "source": [
    "# Fair Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c98dc0b-feb9-4426-9c06-0944fb4cbab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 01:02:17.249084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /modules/apps/julia/1.7.2/lib\n",
      "2022-10-17 01:02:17.249153: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.datasets import AdultDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aif360.datasets import StructuredDataset, BinaryLabelDataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca67f2d-882e-4b76-a1e8-967d110ce837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_feature_encoder(data,features):\n",
    "    '''\n",
    "    takes a data frame and returns numerical encoding for categorical features\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : csv file \n",
    "    features : list of categorical features\n",
    "\n",
    "    Return \n",
    "    ------\n",
    "    returns : dataframe with encoded features, encoding for categorical features  \n",
    "    '''\n",
    "    enc = {}\n",
    "    \n",
    "    for f in features:\n",
    "        encoder = OrdinalEncoder()\n",
    "        data[f] = encoder.fit_transform(data[[f]]).astype(int)\n",
    "        enc[f] = encoder\n",
    "    return data, enc\n",
    "\n",
    "#feature_encoded_data = categorical_feature_encoder(data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941cbf98-2a40-406c-a245-6237131f0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_model(data, subset_cols, target, p_att):\n",
    "    \n",
    "    '''\n",
    "    takes encoded df and formats into a binary label df format to split and return test and train df.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    dataset: original data \n",
    "    subset_cols : columns from dictionary generated from feature selection technique\n",
    "    target : proxy target\n",
    "    p_att: single protected attribute, key from dictionary generated from feature selection technique\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : dataset_orig_train, dataset_orig_test -- test and trained datasets \n",
    "    '''\n",
    "    \n",
    "    #subset_sex_cols = ['education-num', 'capital-gain', 'capital-loss', 'hours-per-week','education', \n",
    "    #'native-country', 'workclass','sex','income-per-year']\n",
    "    encoded_df = data.copy()\n",
    "    structured_data = BinaryLabelDataset(favorable_label=1.0, unfavorable_label=0.0, df = encoded_df[subset_cols]\\\n",
    "                                         .dropna(), label_names = [target], protected_attribute_names = [p_att], \\\n",
    "                                         instance_weights_name=None, scores_names=[], unprivileged_protected_attributes\\\n",
    "                                         =[[0]], privileged_protected_attributes=[[1]], metadata=None)\n",
    "    dataset_orig = structured_data\n",
    "    privileged_groups = [{p_att: 1}] #male \n",
    "    unprivileged_groups = [{p_att: 0}] #female\n",
    "\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "    scaler = StandardScaler()\n",
    "    dataset_orig_train.features = scaler.fit_transform(dataset_orig_train.features)\n",
    "    dataset_orig_test.features = scaler.transform(dataset_orig_test.features) \n",
    "    return dataset_orig_train,dataset_orig_test\n",
    "\n",
    "#dataset_orig_train,dataset_orig_test = fair_model(data, subset_cols, target, p_att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f730ea35-a5f7-439d-9695-2aecde60b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_metrics_fc(dataset_orig_train,dataset_orig_test,p_att,privileged_groups,unprivileged_groups,etas):\n",
    "    \n",
    "    '''\n",
    "    takes train and test dataset runs using PrejudiceRemover classifier and returns fairness metrics\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    dataset_orig_train: training data set \n",
    "    dataset_orig_test: test dataset\n",
    "    p_att: single protected attribute, chooses particular key from dictionary generated from feature selection technique\n",
    "    privileged_groups : list of priviliged values in society eg. male priviliged = [1]\n",
    "    unprivileged_groups : list of unpriviliged values in society eg. female unpriviliged = [0]\n",
    "    etas : fairness penalty parameter\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : fairness metrics \n",
    "    '''\n",
    "    \n",
    "    #etas = [1]\n",
    "    outputs = []\n",
    "    #print(dataset_orig_train,dataset_orig_test,p_att,privileged_groups,unprivileged_groups,etas)\n",
    "    \n",
    "    for eta in etas:\n",
    "        debiased_model = PrejudiceRemover(eta=eta, sensitive_attr = p_att, class_attr=dataset_orig_train.label_names[0])        \n",
    "        model = debiased_model.fit(dataset_orig_train)\n",
    "        pred = model.predict(dataset_orig_test)\n",
    "\n",
    "        metric = ClassificationMetric(dataset_orig_test, pred, unprivileged_groups=unprivileged_groups, \\\n",
    "                                      privileged_groups=privileged_groups)\n",
    "        \n",
    "        outputs.append([eta,metric.disparate_impact(),metric.statistical_parity_difference(),\\\n",
    "                        metric.equal_opportunity_difference(),\\\n",
    "                        accuracy_score(pred.labels, dataset_orig_test.labels)])\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeac561-d71b-44be-a73c-60c8d85cfe57",
   "metadata": {},
   "source": [
    "\n",
    "### Feature selection technique - XY > XA : this technique generates dictionary with keys as protected att and values as features (all features where XY>XA for the particular protected att). We use the values (features) as subsets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40902067-79bc-423f-9019-2da06715ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8261c0-b9ab-4ea9-95d5-4e947df3ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features segregation \n",
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation', 'native-country'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08edb81-5fcc-4777-aa18-c2fff41d96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the categorical columns, OrdinalEncoder - each unique category value is assigned an integer value\n",
    "def categorical_feature_encoder(data,features):\n",
    "    '''\n",
    "    takes a data frame and returns numerical encoding for categorical features\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    dataset: csv file \n",
    "    features : list of categorical features\n",
    "\n",
    "    Return \n",
    "    ------\n",
    "    returns : dataframe with encoded features, encoding for categorical features  \n",
    "    '''\n",
    "    enc = {}\n",
    "    \n",
    "    for f in features:\n",
    "        encoder = OrdinalEncoder()\n",
    "        data[f] = encoder.fit_transform(data[[f]]).astype(int)\n",
    "        enc[f] = encoder\n",
    "    return data, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824db0a3-da7e-47df-a404-fea9ebbcc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating mutual information score for each X (features) and Y (target)\n",
    "def calculate_miscore_xy(data, y_col,a_col):\n",
    "    '''\n",
    "    takes a data frame and returns a data frame with mutual information score between X(features) and Y(target)\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : csv file \n",
    "    y_col : target column\n",
    "    a_col : protected attributes \n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : returns mutual information score between X(features) and Y(target) in a dataframe \n",
    "    '''\n",
    "    mis_xy = []\n",
    "    x_cols = []\n",
    "    for x in data.columns:\n",
    "        if not (x in a_col): # skipping the demographic features \n",
    "            mis = mutual_info_score(data[x], data[y_col], contingency=None) # mis calculation\n",
    "            mis_xy.append(mis) \n",
    "            x_cols.append(x)\n",
    "\n",
    "\n",
    "    adult_dataFrame_feature_target = pd.DataFrame({'I(Xi,Y)': mis_xy, 'X': x_cols}) # creating pandas dataframe\n",
    "    adult_dataFrame_feature_target = adult_dataFrame_feature_target.loc[adult_dataFrame_feature_target['X'] != y_col]#loc : filtering dataframe based on index\n",
    "    adult_dataFrame_feature_target['Y'] = y_col # adding y column\n",
    "    return adult_dataFrame_feature_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c2caf42-d25c-49e0-bc22-9d54d40f55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating mutual information score for each X (features) and A (demographic variables)\n",
    "\n",
    "def calculate_miscore_xa(data,protected_attributes):\n",
    "    '''\n",
    "    takes a data frame and returns a data frame with mutual information score between X(features) and A(protected attributes)\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    dataset: csv file \n",
    "    protected_attributes : protected attributes \n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : returns mutual information score between X(features) and A(protected attributes) in a dataframe \n",
    "    '''\n",
    "    \n",
    "    mis_xa = []\n",
    "    attribute_unfiltered = []\n",
    "    feature_unfiltered = []\n",
    "    for x in data.columns:\n",
    "        for a in protected_attributes:\n",
    "            if not (x in protected_attributes):\n",
    "                mis = mutual_info_score(data[a], data[x], contingency=None)\n",
    "                mis_xa.append(mis)\n",
    "                attribute_unfiltered.append(a)  \n",
    "                feature_unfiltered.append(x)\n",
    "\n",
    "    unfiltered_mis_adult_dataFrame = pd.DataFrame({'X':feature_unfiltered, 'A':attribute_unfiltered, \\\n",
    "                                                   'I(Xi,A)': mis_xa})\n",
    "    return unfiltered_mis_adult_dataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f44342-5172-4485-84da-6def60b748ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dataframes\n",
    "def generate_xy_greater_xa(data1,data2):\n",
    "    '''\n",
    "    takes two data frames (in our case two df generated for I(X,Y) and I(X,A) and returns a dictionary with keys as protected att and values as features \n",
    "    (features = all features where XY>XA for a particular protected att)\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data1: dataframe \n",
    "    data2: dataframe\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : dictionary with key as p attributes and values as features\n",
    "    '''\n",
    "    merged_xiY_xiA = pd.merge(data1,data2, on=['X'], how = 'inner') \n",
    "    merged_xiY_xiA\n",
    "    merged_xiY_xiA.to_csv('merged_xiY_xiA.csv')\n",
    "    #adding a new bool column, True if xi_A > xi_Y\n",
    "    merged_xiY_xiA['X_sub_A = True'] = merged_xiY_xiA['I(Xi,A)'] > merged_xiY_xiA['I(Xi,Y)']\n",
    "\n",
    "    # for each val of A pick list of features where XY>XA - X_sub_A¯\n",
    "    dictonary_xy_greaterthan_xa = {} \n",
    "    for a_v, df_a in merged_xiY_xiA.groupby('A'):\n",
    "        dictonary_xy_greaterthan_xa[a_v] = df_a[df_a['X_sub_A = True']== False]['X'].values\n",
    "\n",
    "    return dictonary_xy_greaterthan_xa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5f133-20a5-4c4a-82ba-72520b371eda",
   "metadata": {},
   "source": [
    "# Criteria 1\n",
    "### feature selection technique -- called in main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "330f82a3-e966-4ec7-9942-b19a6b9e237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_greater_xa(data,features_cat,features_num,protected_attributes, target):\n",
    "    '''\n",
    "    takes data and returns encoded df and a dictionary with keys as protected att and values as features \n",
    "    (features = all features where XY>XA for a particular protected att) \n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : original dataframe\n",
    "    features_cat: list of categorical features in data \n",
    "    protected_attributes : list of protected attributes in data\n",
    "    target: proxy target\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : encoded dataframe and a dictionary\n",
    "    '''\n",
    "    features_encoded_data,enc = categorical_feature_encoder(data.copy(),features_cat + protected_attributes)\n",
    "    features_encoded_data = features_encoded_data[features_cat + features_num + protected_attributes + [target]]\n",
    "\n",
    "    mi_Xi_Y = calculate_miscore_xy(features_encoded_data, target, protected_attributes)\n",
    "    mi_Xi_A = calculate_miscore_xa(features_encoded_data,protected_attributes)\n",
    "    dict_subsets_xy_greaterthan_xa = generate_xy_greater_xa(mi_Xi_Y,mi_Xi_A) \n",
    "    return features_encoded_data, dict_subsets_xy_greaterthan_xa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e32487-c344-4204-b982-98cea15540e8",
   "metadata": {},
   "source": [
    "# Criteria 2\n",
    "### Maximally demographic informative subspace (sequential forward and sequential backward search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8737ca2-c874-4b8c-b9a1-5e10a1d30888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MiEstimator():\n",
    "        '''\n",
    "        MI estimator for calculating the mutual information score between XY and XA.\n",
    "\n",
    "        Parameters: \n",
    "        ----------- \n",
    "        X : data\n",
    "        protected_attributes (A/Y): demographic attributed in data or target variable, while calling the method A/Y can be used as per requirement.\n",
    "        bins : dividing number of groups with respect to respective features.\n",
    "\n",
    "        Return \n",
    "        ------\n",
    "        returns : returns a single value of MI XY or MI XA   \n",
    "        '''\n",
    "    \n",
    "    def __init__(self,protected_attributes, bins):\n",
    "        self.protected_attributes = protected_attributes\n",
    "        self.bins = bins # will contain a dict for cutting into bins (dictionary)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return X\n",
    "        \n",
    "    def score(self, X):\n",
    "        mis_xa = []\n",
    "        if self.protected_attributes!= 'age':\n",
    "            target_bins = X[self.protected_attributes].nunique()\n",
    "        else:\n",
    "            target_bins = 5\n",
    "        xa_mat, bins = np.histogramdd(X[list(X.columns) + [self.protected_attributes]].values,[self.bins[j] for j in X.columns]+[target_bins]) \n",
    "        xalist = xa_mat.reshape(-1,target_bins)\n",
    "        mis_a = mutual_info_score(None, None, contingency = xalist)\n",
    "        return mis_a \n",
    "    \n",
    "    def get_params(self,deep=True):\n",
    "        return {'protected_attributes':self.protected_attributes,'bins':self.bins}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb26a07-1ddb-460d-99cd-7f7ae44784e5",
   "metadata": {},
   "source": [
    "### Forward sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d28ebb7a-3317-49b5-b660-7d4ad63254b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_feature_selection_forward(data,features_cat,features_num,protected_attributes, target): # add feat_dictionary as argument\n",
    "    #return \n",
    "    '''\n",
    "    this criteria works in a forward sequential manner to select relevant and fair sub sets of features based on mutual information calculation.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : original dataframe\n",
    "    features_cat: list of categorical features in data\n",
    "    features_num: list of numerical features in data\n",
    "    protected_attributes : list of protected attributes in data\n",
    "    target: proxy target\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : returns features selected by sfs as values of protected attribute(key) in use   \n",
    "    '''\n",
    "    # feat_dictionary is a dictionaly which contains features as keys and values as number of bins.\n",
    "    feat_dictionary= {'hours-per-week':3,'capital-gain':10,'capital-loss':5,'education-num':5 ,'workclass':7,'education':16, 'relationship':6, 'occupation':14 }\n",
    "    features_encoded_data,enc = categorical_feature_encoder(data.copy(),features_cat + protected_attributes)\n",
    "    dictionary_features = {}\n",
    "    for att in protected_attributes:\n",
    "        mie = MiEstimator(att,feat_dictionary)\n",
    "        #print(features_encoded_data[features_cat+features_num].info())\n",
    "        sfs = SequentialFeatureSelector(mie, n_features_to_select= \"auto\")\n",
    "        sfs.fit(features_encoded_data[features_cat+features_num])\n",
    "        mask = sfs.get_support()\n",
    "        dictionary_features[att] = [(features_cat+features_num)[i] for i in range(len(mask)) if not mask[i]] \n",
    "        #print('dictionary_features',dictionary_features)\n",
    "    return features_encoded_data, dictionary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee7961-8a6b-4f2b-84fb-8db9e24fcb0a",
   "metadata": {},
   "source": [
    "### Backward sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca79c8d-526a-4fd8-b8cf-3268b4a16bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_feature_selection_backward(data,features_cat,features_num,protected_attributes, target):\n",
    "    '''\n",
    "    this criteria works in a backward sequential manner to select relevant and fair sub sets of features based on mutual information calculation.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : original dataframe\n",
    "    features_cat: list of categorical features in data\n",
    "    features_num: list of numerical features in data\n",
    "    protected_attributes : list of protected attributes in data\n",
    "    target: proxy target\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : returns features selected by sfs backward as values of protected attribute(key) in use   \n",
    "    '''\n",
    "    \n",
    "    feat_dictionary= {'hours-per-week':3,'capital-gain':10,'capital-loss':5,'education-num':5 ,'workclass':7,'education':16, 'relationship':6, 'occupation':14 }\n",
    "    features_encoded_data,enc = categorical_feature_encoder(data.copy(),features_cat + protected_attributes)\n",
    "    dictionary_features = {}\n",
    "    for att in protected_attributes:\n",
    "        mie = MiEstimator(att,feat_dictionary)\n",
    "        #print(features_encoded_data[features_cat+features_num].info())\n",
    "\n",
    "        sfs = SequentialFeatureSelector(mie, direction = 'backward', n_features_to_select= \"auto\")\n",
    "        sfs.fit(features_encoded_data[features_cat+features_num])\n",
    "        mask = sfs.get_support()\n",
    "        dictionary_features[att] = [(features_cat+features_num)[i] for i in range(len(mask)) if not mask[i]] \n",
    "        #print('dictionary_features',dictionary_features)\n",
    "    return features_encoded_data, dictionary_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9462e5e-8cec-46fe-bdfb-7d368f06fee4",
   "metadata": {},
   "source": [
    "# Criteria 3\n",
    "## Maximally predictive, minimally demographic\n",
    "\n",
    "- inspired MRMR - maximal relevance minimum redundancy\n",
    "\n",
    "- look at subset or group-wise feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31029587-03b7-40c6-98ba-f80382bc0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score(X, bins,protected_attributes): # In case of target, protected attributes = target\n",
    "    '''\n",
    "    Computes MI score\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    X : dataframe\n",
    "    bins: \n",
    "    protected_attributes : list of protected attributes in data\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : returns calculated MI column from data  \n",
    "    '''\n",
    "        mis_xa = []\n",
    "        for feat, num_bins in bins.items():\n",
    "            if protected_attributes!= 'age':\n",
    "                target_bins = X[protected_attributes].nunique()\n",
    "            else:\n",
    "                target_bins = 5\n",
    "            xy_mat, bins = np.histogramdd(X[[feat,protected_attributes]].values, [num_bins,target_bins])\n",
    "            xylist = xy_mat.reshape(-1,target_bins)\n",
    "            mis_a = mutual_info_score(None, None, contingency = xylist)\n",
    "            mis_xa.append([feat,mis_a])\n",
    "        dataframe = pd.DataFrame(mis_xa,columns = ['feat','mi']).set_index('feat')\n",
    "        return dataframe['mi']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbf36749-8d0a-49e1-abd4-57c54f5c570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximally_predictive_minimally_demographic(data,features_cat,features_num,protected_attributes, target): # add feat_dictionary\n",
    "    '''\n",
    "    Computes MI using score function for both XA and XY and by taking the ration selects K relevant and fair features.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : dataframe\n",
    "    features_cat: list of categorical features in data\n",
    "    features_num : list of numerical features in data\n",
    "    protected_attributes : list of protected attributes in data\n",
    "    target : proxy target\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : returns dictionary with values as subset of features and keys as protected attribute in use  \n",
    "    '''\n",
    "    #MI beteen X and Y and MI between X and A and do the ration\n",
    "    \n",
    "    feat_dictionary= {'hours-per-week':3,'capital-gain':10,'capital-loss':5,'education-num':5 ,'workclass':7,'education':16, 'relationship':6, 'occupation':14 }\n",
    "\n",
    "    features_encoded_data,enc = categorical_feature_encoder(data.copy(),features_cat + protected_attributes)\n",
    "    dictionary_features = {}\n",
    "    for att in protected_attributes:\n",
    "        # compute F-statistics\n",
    "        F = score(features_encoded_data, feat_dictionary,target)\n",
    "        FA = score(features_encoded_data,feat_dictionary,att)\n",
    "        F = F/FA\n",
    "        F = F.sort_values(ascending = False)\n",
    "        k = int(F.shape[0]/1.5) #size of features\n",
    "        F = F.iloc[:k]\n",
    "        dictionary_features[att] = list(F.index.values)\n",
    "    return features_encoded_data, dictionary_features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f6eba-5bcc-47ec-8c43-bdcb31e63a60",
   "metadata": {},
   "source": [
    "### Model functions for selecting a particular model -- both can be called in main function by specifying model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce3dd3ab-76e3-40d1-b45b-15b06d7d385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_classifier(features_encoded_data,target,p_att_col,model_cols,filtered_col, etas): # etas not in use but passing for consistency of format\n",
    "    '''\n",
    "    takes encoded df, runs logistic regression on the data to return a df consiting of fairness metrics and model type column.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    features_encoded_data: encoded dataframe from categorical_feature_encoder function \n",
    "    target: proxy target\n",
    "    p_att_col : protected attributes in the data\n",
    "    model_cols : specific subset used from the data for analysis\n",
    "    filtered_col : used for filtering columns based on conditions eg. keeping black(0) and white(1) in race column and removing other races.\n",
    "    etas : fairness penalty parameter, not used in base classifier\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : fairness metric dataframe \n",
    "    '''\n",
    "    original_output = base_model(features_encoded_data[model_cols].copy(),target,p_att_col)\n",
    "    base_classifier_fairness_metrics = get_fairness_metrics_bc(original_output,p_att_col)\n",
    "    return pd.DataFrame([['base_model']+base_classifier_fairness_metrics],columns = ['model_type',\\\n",
    "                                                                                     'disparate_impact',\\\n",
    "                                                                                     'statistical_parity_difference',\\\n",
    "                                                                                     'equal_opportunity_difference',\\\n",
    "                                                                                     'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93283a75-8ba4-4257-a02f-3f5c2a743338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_classifier(features_encoded_data,target,p_att_col,model_cols, filtered_col, etas):\n",
    "    '''\n",
    "    takes encoded df, runs prejudice remover on the data to return a df consiting of fairness metrics and model type column.\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    features_encoded_data: encoded dataframe from categorical_feature_encoder function \n",
    "    target: proxy target\n",
    "    p_att_col : protected attributes in the data\n",
    "    model_cols : specific subset used from the data for analysis\n",
    "    filtered_col : used for filtering columns based on conditions eg. keeping black(0) and white(1) in race column and removing other races.\n",
    "    etas : fairness penalty parameter\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : fairness metric dataframe \n",
    "    '''\n",
    "    print(model_cols)\n",
    "    dataset_orig_train,dataset_orig_test = fair_model(features_encoded_data, model_cols, target, filtered_col)\n",
    "    fair_classifier_fairness_metrics = get_fairness_metrics_fc(dataset_orig_train,dataset_orig_test, \\\n",
    "                                                               filtered_col,privileged_groups = [{filtered_col:1}] ,\\\n",
    "                                                               unprivileged_groups = [{filtered_col:0}],etas=etas)\n",
    "    result = pd.DataFrame(fair_classifier_fairness_metrics,columns = ['eta','disparate_impact',\\\n",
    "                                                                      'statistical_parity_difference',\\\n",
    "                                                                      'equal_opportunity_difference',\\\n",
    "                                                                      'accuracy'])\n",
    "    result.insert(0,'model_type','fair_model')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46916360-fa43-43de-a0d3-f44584724f97",
   "metadata": {},
   "source": [
    "### function for calling models and performing initial manipulation over data based on Protected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0d9db93-444d-4bef-9ea5-c03375d42bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data,features_encoded_data, p_att_col, dict_subsets_xy_greaterthan_xa,target, priviliged_vals, model_type,etas):\n",
    "    '''\n",
    "    build model takes encoded data and handles the data manipulation part prior to modeling phase (used for both fair and base classifier) and \n",
    "    finally runs the model and returns output dataframe with fairness metrics\n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : original dataframe\n",
    "    features_encoded_data: encoded dataframe from categorical_feature_encoder function \n",
    "    target: proxy target\n",
    "    p_att_col : protected attributes in the data\n",
    "    dict_subsets_xy_greaterthan_xa : generated from generate_xy_greater_xa function\n",
    "    target : proxy target\n",
    "    priviliged_vals : priviliged value in a particular protected att, which should be considered as priviliged group. eg. Whites in races can be \n",
    "    considered as priviliged\n",
    "    model_type : fair or base models \n",
    "    etas : fairness penalty parameter for fair model - prejudice remover\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : dataframe \n",
    "    '''\n",
    "    filtered_col = f'filtered_{p_att_col}'\n",
    "    model_cols = [filtered_col] + list(dict_subsets_xy_greaterthan_xa[p_att_col]) + [target]\n",
    "    features_encoded_data = df_manipulation(features_encoded_data,data,p_att_col,priviliged_vals)\n",
    "    output = model_type(features_encoded_data,target,p_att_col,model_cols,filtered_col, etas)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f996608-303a-489b-9d89-19c5f2a2ec5d",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce59a3ce-e814-43af-b5a8-d31e7227d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_exp_bf_func(data,features_cat,features_num,protected_attributes, target, p_att_col, priviliged_vals, etas, \\\n",
    "                     technique = xy_greater_xa, model = fair_classifier):\n",
    "   \n",
    "    '''\n",
    "    takes data and other arguments to return fairness metrics for a particular model and feature selection technique \n",
    "    \n",
    "    Parameters: \n",
    "    ----------- \n",
    "    data : original dataframe\n",
    "    features_cat: list of categorical features in data \n",
    "    protected_attributes : list of protected attributes in data\n",
    "    target: proxy target\n",
    "    p_att_col : single protected attribute we want an analysis for\n",
    "    priviliged_vals : privileged values for feature mentioned in p_att_col\n",
    "    etas : fairness penalty parameter\n",
    "    technique : feature selection technique used for subset generation\n",
    "    model : estimator object, fair or base classifier\n",
    "    \n",
    "    Return \n",
    "    ------\n",
    "    returns : dataframe with model type column and fairness metrics\n",
    "    '''\n",
    "    data_df = data.df \n",
    "    features_encoded_data, dict_subsets_xy_greaterthan_xa = technique(data_df,features_cat,features_num,protected_attributes, target)\n",
    "    return build_model(data_df,features_encoded_data, p_att_col, dict_subsets_xy_greaterthan_xa,target, priviliged_vals, model, etas)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d614e2e-e3f7-405c-8768-cd04354a840e",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ef79a6-0c8e-4ccb-8f46-5005af25a1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income-per-year</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>native-country</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>relationship</th>\n",
       "      <th>workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Black</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Local-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Black</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>White</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0  25.0            7.0  1.0           0.0           0.0            40.0   \n",
       "1  38.0            9.0  1.0           0.0           0.0            50.0   \n",
       "2  28.0           12.0  1.0           0.0           0.0            40.0   \n",
       "3  44.0           10.0  1.0        7688.0           0.0            40.0   \n",
       "4  34.0            6.0  1.0           0.0           0.0            30.0   \n",
       "\n",
       "   income-per-year     education      marital-status native-country  \\\n",
       "0              0.0          11th       Never-married  United-States   \n",
       "1              0.0       HS-grad  Married-civ-spouse  United-States   \n",
       "2              1.0    Assoc-acdm  Married-civ-spouse  United-States   \n",
       "3              1.0  Some-college  Married-civ-spouse  United-States   \n",
       "4              0.0          10th       Never-married  United-States   \n",
       "\n",
       "          occupation   race   relationship  workclass  \n",
       "0  Machine-op-inspct  Black      Own-child    Private  \n",
       "1    Farming-fishing  White        Husband    Private  \n",
       "2    Protective-serv  White        Husband  Local-gov  \n",
       "3  Machine-op-inspct  Black        Husband    Private  \n",
       "4      Other-service  White  Not-in-family    Private  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "adult_df = pd.read_csv('adult_dataset.csv')\n",
    "adult_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "adult_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "981eb17f-2136-45fa-b3bc-cfe683f64ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education-num', 'sex', 'capital-gain', 'capital-loss',\n",
       "       'hours-per-week', 'income-per-year', 'education', 'marital-status',\n",
       "       'native-country', 'occupation', 'race', 'relationship', 'workclass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7839151-69a6-47e8-b6c3-4391fb9df3cd",
   "metadata": {},
   "source": [
    "## Dataset naming function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "863ef079-9805-4035-be98-a39ffbb0c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedDataset():\n",
    "    def __init__(self,name,df):\n",
    "        self.name = name\n",
    "        self.df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e518bea-9344-4a8b-8723-749a30e611db",
   "metadata": {},
   "source": [
    "### Criteria 1 - xy_greater_xa | base classifier, p att = sex, priviliged = male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4c05abf-e7ea-4030-885f-a611d4cecb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filtered_sex', 'workclass', 'education', 'hours-per-week',\n",
      "       'capital-gain', 'capital-loss', 'education-num'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>0.484487</td>\n",
       "      <td>-0.074253</td>\n",
       "      <td>-0.050191</td>\n",
       "      <td>0.801437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  disparate_impact  statistical_parity_difference  \\\n",
       "0  base_model          0.484487                      -0.074253   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                     -0.050191  0.801437  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] # all the numerical fearures\n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] # categorical features\n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year' # proxy target\n",
    "\n",
    "p_att_col = 'sex' # calculating on individual p_att 'sex'\n",
    "priviliged_vals = [1] # [priviliged_vals = [white] for white vs all ; priviliged_vals = [white,asian] if both are considered privileged]\n",
    "model = base_classifier # model\n",
    "technique = xy_greater_xa # feature selection technique\n",
    "etas = [1]\n",
    "\n",
    "\n",
    "\n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c65e5-28e2-4a4c-9d03-94d53bcdf46c",
   "metadata": {},
   "source": [
    "### Criteria 1 - xy_greater_xa | fair classifier, p att = sex, priviliged = male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a90edfbf-e26f-4300-bd15-3c34db8848b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filtered_sex', 'workclass', 'education', 'hours-per-week', 'capital-gain', 'capital-loss', 'education-num', 'income-per-year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>eta</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair_model</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161248</td>\n",
       "      <td>-0.159269</td>\n",
       "      <td>-0.225117</td>\n",
       "      <td>0.816024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  eta  disparate_impact  statistical_parity_difference  \\\n",
       "0  fair_model    1          0.161248                      -0.159269   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                     -0.225117  0.816024  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] # all the numerical fearures\n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] # categorical features\n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year' # proxy target\n",
    "\n",
    "p_att_col = 'sex' # calculating on individual p_att 'sex'\n",
    "priviliged_vals = [1] # [priviliged_vals = [white] for white vs all ; priviliged_vals = [white,asian] if both are considered privileged]\n",
    "model = fair_classifier # model\n",
    "technique = xy_greater_xa # feature selection technique\n",
    "etas = [1]\n",
    "\n",
    "\n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5fb9a-675b-4d35-97f2-4bafb661c6b0",
   "metadata": {},
   "source": [
    "### Criteria 2a - sequential forward selection | base classifier, p att = sex, priviliged = male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bd2e730-643b-4c1f-9cc3-9fdb6b8fcb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filtered_sex', 'hours-per-week', 'capital-gain', 'capital-loss',\n",
      "       'education-num'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>0.479924</td>\n",
       "      <td>-0.073731</td>\n",
       "      <td>-0.04928</td>\n",
       "      <td>0.798894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  disparate_impact  statistical_parity_difference  \\\n",
       "0  base_model          0.479924                      -0.073731   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                      -0.04928  0.798894  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'sex'\n",
    "priviliged_vals = [1] # [white vs all] [white,asian]\n",
    "model = base_classifier\n",
    "technique = sequential_feature_selection_forward\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677bcd5-4ccf-453a-a0ab-9001acd818c3",
   "metadata": {},
   "source": [
    "### Criteria 2a - sequential forward selection | fair classifier, p att = sex, priviliged = male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13bf4390-925e-4f8a-b89b-87ac671f32b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filtered_sex', 'hours-per-week', 'capital-gain', 'capital-loss', 'education-num', 'income-per-year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>eta</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair_model</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>-0.145714</td>\n",
       "      <td>-0.195367</td>\n",
       "      <td>0.80939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  eta  disparate_impact  statistical_parity_difference  \\\n",
       "0  fair_model    1          0.172958                      -0.145714   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                     -0.195367   0.80939  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'sex'\n",
    "priviliged_vals = [1] # [white vs all] [white,asian]\n",
    "model = fair_classifier\n",
    "technique = sequential_feature_selection_forward\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948f1ee-22f1-4e6c-bd2a-7f7c3a10f4e7",
   "metadata": {},
   "source": [
    "### Criteria 2b - sequential backward selection | base classifier , p att = sex, priviliged = male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b8e4499-5b2c-4bd0-867f-169eec42a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filtered_sex', 'workclass', 'education', 'relationship', 'occupation'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  disparate_impact  statistical_parity_difference  \\\n",
       "0  base_model               inf                            0.0   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                           0.0  0.748811  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not working for backward for any protected attributes\n",
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'sex'\n",
    "priviliged_vals = [1] # [white vs all] [white,asian]\n",
    "model = base_classifier\n",
    "technique = sequential_feature_selection_backward\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ff578-2d02-40f0-8ac4-b1900121665a",
   "metadata": {},
   "source": [
    "### Criteria 2b - sequential backward selection | base classifier , p att = race, priviliged = white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9e71966-5d35-46c4-83f8-350be65a7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filtered_race', 'workclass', 'education', 'relationship',\n",
      "       'occupation'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  disparate_impact  statistical_parity_difference  \\\n",
       "0  base_model               inf                            0.0   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                           0.0  0.748811  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not working for backward for any protected attributes\n",
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'race'\n",
    "priviliged_vals = ['White'] # [white vs all] [white,asian]\n",
    "model = base_classifier\n",
    "technique = sequential_feature_selection_backward\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7baf2f4-4ea9-44d8-9b0c-55d9188fef77",
   "metadata": {},
   "source": [
    "### Criteria 2b - sequential backward selection | base classifier , p att = marital-status, priviliged = Married-civ-spouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "183ea559-d213-436f-bea2-912b7c4b0859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filtered_marital-status', 'workclass', 'education', 'relationship',\n",
      "       'occupation'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  disparate_impact  statistical_parity_difference  \\\n",
       "0  base_model               inf                            0.0   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                           0.0  0.748811  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not working for backward for any protected attributes\n",
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'marital-status'\n",
    "priviliged_vals = ['Married-civ-spouse'] # [white vs all] [white,asian]\n",
    "model = base_classifier\n",
    "technique = sequential_feature_selection_backward\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1863f-1118-4b5c-b591-2580ab55a9c6",
   "metadata": {},
   "source": [
    "### Criteria 2b - sequential backward selection | fair classifier , p att = sex, priviliged = male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcd0bb69-1bb0-4bae-a13a-33423d409f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filtered_sex', 'workclass', 'education', 'relationship', 'occupation', 'income-per-year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>eta</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair_model</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>-0.043064</td>\n",
       "      <td>-0.064034</td>\n",
       "      <td>0.74895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  eta  disparate_impact  statistical_parity_difference  \\\n",
       "0  fair_model    1          0.020564                      -0.043064   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                     -0.064034   0.74895  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'sex'\n",
    "priviliged_vals = [1] # [white vs all] [white,asian]\n",
    "model = fair_classifier\n",
    "technique = sequential_feature_selection_backward\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7b867-e0c1-4094-8099-30b778df3450",
   "metadata": {},
   "source": [
    "### Criteria 3 - maximally_predictive_minimally_demographic | base classifier, p att = race, priviliged = 'White'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "101d7121-7dd8-4eef-af8a-eee1aa7453e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filtered_race', 'capital-gain', 'hours-per-week', 'capital-loss',\n",
      "       'relationship', 'education-num'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>0.595248</td>\n",
       "      <td>-0.061716</td>\n",
       "      <td>-0.059123</td>\n",
       "      <td>0.814151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  disparate_impact  statistical_parity_difference  \\\n",
       "0  base_model          0.595248                      -0.061716   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                     -0.059123  0.814151  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'race'\n",
    "priviliged_vals = ['White'] # [white vs all] [white,asian]\n",
    "model = base_classifier\n",
    "technique = maximally_predictive_minimally_demographic\n",
    "etas = [1]\n",
    "\n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a37ce-2f57-47e4-b71c-451eb7663224",
   "metadata": {},
   "source": [
    "### Criteria 3 - maximally_predictive_minimally_demographic | fair classifier, p att = race, priviliged = 'White'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50a4f2b9-e3f8-46ca-b48c-c9798539d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filtered_race', 'capital-gain', 'hours-per-week', 'capital-loss', 'relationship', 'education-num', 'income-per-year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>eta</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fair_model</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497339</td>\n",
       "      <td>-0.077827</td>\n",
       "      <td>-0.069419</td>\n",
       "      <td>0.820004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  eta  disparate_impact  statistical_parity_difference  \\\n",
       "0  fair_model    1          0.497339                      -0.077827   \n",
       "\n",
       "   equal_opportunity_difference  accuracy  \n",
       "0                     -0.069419  0.820004  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'race'\n",
    "priviliged_vals = ['White'] # [white vs all] [white,asian]\n",
    "model = fair_classifier\n",
    "technique = maximally_predictive_minimally_demographic\n",
    "etas = [1]\n",
    "\n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "main_exp_bf_func(adult_dataset,features_cat,features_num,protected_attributes, target, p_att_col, \\\n",
    "                 priviliged_vals , etas, technique, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c76125-c1e2-4481-a18a-c8351c312091",
   "metadata": {},
   "source": [
    "## Exp tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e26cd64e-9425-416c-bbf2-b648513253e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.mkdir('results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "630f8658-5ce3-4485-a3a4-fc6e474c8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debiased_model = PrejudiceRemover(eta=eta, sensitive_attr = p_att, class_attr=dataset_orig_train.label_names[0])\n",
    "features_num = ['hours-per-week', 'capital-gain', 'capital-loss','education-num' ] \n",
    "features_cat =  ['workclass','education', 'relationship', 'occupation', 'native-country'] \n",
    "protected_attributes = ['sex','race','age', 'marital-status']\n",
    "target = 'income-per-year'\n",
    "\n",
    "p_att_col = 'sex'\n",
    "priviliged_vals = [1] # [white vs all] [white,asian]\n",
    "model = base_classifier\n",
    "technique = xy_greater_xa\n",
    "etas = [1]\n",
    "        \n",
    "adult_dataset = NamedDataset('adult',adult_df)\n",
    "\n",
    "\n",
    "thesis_param_grid = {'data':[adult_dataset],'features_cat': [features_cat], \\\n",
    "                     'protected_attributes':[protected_attributes],\\\n",
    "                     'target': [target], 'p_att_col': [p_att_col],'priviliged_vals':\\\n",
    "                     [priviliged_vals] , 'etas': [etas], \\\n",
    "                     'technique': [technique], 'model': [model]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b55d4930-1e48-4e2e-99ce-298399b8c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_function(cur_param):\n",
    "    name_parts = []\n",
    "    name_parts.append(cur_param['data'].name) \n",
    "    # some short version of features\n",
    "    name_parts.append(cur_param['technique'].__name__)\n",
    "    name_parts.append(cur_param['model'].__name__)\n",
    "    return '_'.join(name_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ae3790d-a6b9-4a55-bccd-f9168f3b83b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xy_greater_xa'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technique.__name__ # run to see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1319ff9f-31e9-4e3f-b7f4-dae2855d57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_expt = Experiment(main_exp_bf_func,thesis_param_grid)\n",
    "batchname, successes ,fails = my_expt.run_batch(expt_name = 'thesis_feature_selection',\n",
    "                                               name_func = name_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9c11af1-d653-4df3-b129-8f4a5a1f464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27b91de3-2863-42a4-9b8c-b7906fc80bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a func that takes param_grid and generates a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98738a2d-3bd4-4de6-ab96-3b68dba1ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (root)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
